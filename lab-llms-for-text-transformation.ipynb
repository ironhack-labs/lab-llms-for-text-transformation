{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs for Text Transformation\n",
    "\n",
    "In this notebook, we will explore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.51.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0): \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "ChatGPT is trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, me gustaría ordenar una licuadora.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish: \\ \n",
    "```Hi, I would like to order a blender```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is French.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me which language this is: \n",
    "```Combien coûte le lampadaire?```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Je veux commander un ballon de basket\n",
      "Spanish: Quiero ordenar un balón de baloncesto\n",
      "English: I want to order a basketball\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following  text to French and Spanish\n",
    "and English pirate: \\\n",
    "```I want to order a basketball```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal: ¿Le gustaría ordenar una almohada?\n",
      "Informal: ¿Te gustaría ordenar una almohada?\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following text to Spanish in both the \\\n",
    "formal and informal forms: \n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Translator\n",
    "Imagine you are in charge of IT at a large multinational e-commerce company. Users are messaging you with IT issues in all their native languages. Your staff is from all over the world and speaks only their native languages. You need a universal translator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
    "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message (This is French.): La performance du système est plus lente que d'habitude.\n",
      "English: \"The system performance is slower than usual.\"\n",
      "\n",
      "Korean: \"시스템 성능이 평소보다 느립니다.\" \n",
      "\n",
      "Original message (This is Spanish.): Mi monitor tiene píxeles que no se iluminan.\n",
      "English: \"My monitor has pixels that do not light up.\"\n",
      "Korean: \"내 모니터에는 빛나지 않는 픽셀이 있습니다.\" \n",
      "\n",
      "Original message (Italian): Il mio mouse non funziona\n",
      "English: My mouse is not working\n",
      "Korean: 내 마우스가 작동하지 않습니다 \n",
      "\n",
      "Original message (This is Polish.): Mój klawisz Ctrl jest zepsuty\n",
      "English: My Ctrl key is broken\n",
      "Korean: 제 Ctrl 키가 고장 났어요 \n",
      "\n",
      "Original message (This is Chinese.): 我的屏幕在闪烁\n",
      "English: My screen is flickering\n",
      "Korean: 내 화면이 깜박거립니다 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Transformation\n",
    "Writing can vary based on the intended audience. ChatGPT can produce different tones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir/Madam,\n",
      "\n",
      "I am writing to bring to your attention the specifications of the standing lamp. \n",
      "\n",
      "Sincerely,\n",
      "Joe\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter: \n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Conversion\n",
    "ChatGPT can translate between formats. The prompt should describe the input and output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "  <title>Restaurant Employees</title>\n",
      "</head>\n",
      "<body>\n",
      "  <table>\n",
      "    <tr>\n",
      "      <th>Name</th>\n",
      "      <th>Email</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Shyam</td>\n",
      "      <td>shyamjaiswal@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Bob</td>\n",
      "      <td>bob32@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Jai</td>\n",
      "      <td>jai87@gmail.com</td>\n",
      "    </tr>\n",
      "  </table>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "data_json = { \"resturant employees\" :[ \n",
    "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
    "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following python dictionary from JSON to an HTML \\\n",
    "table with column headers and title: {data_json}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "  <title>Restaurant Employees</title>\n",
       "</head>\n",
       "<body>\n",
       "  <table>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shyam</td>\n",
       "      <td>shyamjaiswal@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bob</td>\n",
       "      <td>bob32@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jai</td>\n",
       "      <td>jai87@gmail.com</td>\n",
       "    </tr>\n",
       "  </table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spellcheck/Grammar check.\n",
    "\n",
    "Here are some examples of common grammar and spelling problems and the LLM's response. \n",
    "\n",
    "To signal to the LLM that you want it to proofread your text, you instruct the model to 'proofread' or 'proofread and correct'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The girl with the black and white puppies has a ball.\n",
      "No errors found\n",
      "No errors found.\n",
      "Their goes my freedom. There going to bring they’re suitcases.\n",
      "\n",
      "No errors found.\n",
      "\n",
      "Rewritten:\n",
      "Their goes my freedom. There going to bring their suitcases.\n",
      "You're going to need your notebook.\n",
      "No errors found.\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
    "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
    "  \"Your going to need you’re notebook.\",  # Homonyms\n",
    "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
    "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"Proofread and correct the following text\n",
    "    and rewrite the corrected version. If you don't find\n",
    "    and errors, just say \"No errors found\". Don't use \n",
    "    any punctuation around the text:\n",
    "    ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same price. It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Got this for my daughter for her birthday cuz she keeps taking \\\n",
    "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
    "it everywhere with her, and it's super soft and cute.  One of the \\\n",
    "ears is a bit lower than the other, and I don't think that was \\\n",
    "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
    "though. I think there might be other options that are bigger for \\\n",
    "the same price.  It arrived a day earlier than expected, so I got \\\n",
    "to play with it myself before I gave it to my daughter.\n",
    "\"\"\"\n",
    "prompt = f\"proofread and correct this review: ```{text}```\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redlines\n",
      "  Downloading redlines-0.4.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from redlines) (8.1.7)\n",
      "Collecting rich<14.0.0,>=13.3.5 (from redlines)\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rich-click<2.0.0,>=1.6.1 (from redlines)\n",
      "  Downloading rich_click-1.8.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=13.3.5->redlines)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.3.5->redlines) (2.17.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from rich-click<2.0.0,>=1.6.1->redlines) (4.12.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.3.5->redlines)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading redlines-0.4.2-py3-none-any.whl (8.0 kB)\n",
      "Downloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich_click-1.8.3-py3-none-any.whl (35 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, markdown-it-py, rich, rich-click, redlines\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 redlines-0.4.2 rich-13.9.2 rich-click-1.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    " ! pip3 install redlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red;font-weight:700;text-decoration:line-through;'>Got </span><span style='color:green;font-weight:700;'>I got </span>this for my daughter for her birthday <span style='color:red;font-weight:700;text-decoration:line-through;'>cuz </span><span style='color:green;font-weight:700;'>because </span>she keeps taking mine from my <span style='color:red;font-weight:700;text-decoration:line-through;'>room.  </span><span style='color:green;font-weight:700;'>room. </span>Yes, adults also like pandas <span style='color:red;font-weight:700;text-decoration:line-through;'>too.  </span><span style='color:green;font-weight:700;'>too. </span>She takes it everywhere with her, and it's super soft and <span style='color:red;font-weight:700;text-decoration:line-through;'>cute.  </span><span style='color:green;font-weight:700;'>cute. </span>One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same <span style='color:red;font-weight:700;text-decoration:line-through;'>price.  </span><span style='color:green;font-weight:700;'>price. </span>It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "\n",
    "diff = Redlines(text,response)\n",
    "display(Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I purchased this adorable panda plush for my daughter's birthday as she kept borrowing mine from my room. It's not just for kids - even adults can appreciate the charm of pandas. The plush is incredibly soft and cute, making it the perfect companion for my daughter wherever she goes. However, I did notice that one of the ears is slightly lower than the other, which seems like a design flaw rather than intentional asymmetry. Additionally, considering the price I paid, I found the plush to be a bit smaller than expected. I believe there are larger options available for the same price point. Despite this, I was pleasantly surprised when the plush arrived a day earlier than anticipated, allowing me to enjoy it myself before gifting it to my daughter. Overall, while there are some minor flaws, the quality and cuteness of this panda plush make it a worthwhile purchase for any panda lover, young or old."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "proofread and correct this review. Make it more compelling. \n",
    "Ensure it follows APA style guide and targets an advanced reader. \n",
    "Output in markdown format.\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Sentiment\": \"positive\",\n",
      "    \"Anger\": false,\n",
      "    \"Item\": \"lamp\",\n",
      "    \"Brand\": \"Lumina\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Version 1: Multi-task Inference from Product Review\n",
    "# This version focuses on extracting multiple pieces of information in one go, including the sentiment,\n",
    "# whether anger is expressed, and identifying the product and the brand.\n",
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast. The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together. I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text: \n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer had a positive experience with Lumina's customer service. They received a replacement part quickly and found the company to be caring and responsive to their needs.\n"
     ]
    }
   ],
   "source": [
    "# Version 2: Summarizing Product Reviews with a Focus on Customer Service\n",
    "# This version asks the model to summarize the review, focusing specifically on the customer service aspect.\n",
    "prompt = f\"\"\"\n",
    "Summarize the following product review with a focus on customer service experience.\n",
    "The review is delimited with triple backticks.\n",
    "\n",
    "Review: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"nasa\": 1,\n",
      "    \"local government\": 0,\n",
      "    \"engineering\": 0,\n",
      "    \"employee satisfaction\": 1,\n",
      "    \"federal government\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Version 3: Inferring Topics from a News Article\n",
    "# This version focuses on inferring topics discussed in a news article, as well as determining which predefined topics are present in the text.\n",
    "news_story = \"\"\"\n",
    "In a recent survey conducted by the government, public sector employees were asked to rate their level of satisfaction with the department they work at. The results revealed that NASA was the most popular department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings, stating, \"I'm not surprised that NASA came out on top. It's a great place to work with amazing people and incredible opportunities. I'm proud to be a part of such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team, with Director Tom Johnson stating, \"We are thrilled to hear that our employees are satisfied with their work at NASA. We have a talented and dedicated team who work tirelessly to achieve our goals, and it's fantastic to see that their hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the Social Security Administration had the lowest satisfaction rating, with only 45% of employees indicating they were satisfied with their job. The government has pledged to address the concerns raised by employees in the survey and work towards improving job satisfaction across all departments.\n",
    "\"\"\"\n",
    "\n",
    "topic_list = [\"nasa\", \"local government\", \"engineering\", \"employee satisfaction\", \"federal government\"]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as a dictionary where the key is a topic and the value is 0 or 1 for each topic if it appears in the text.\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text: '''{news_story}'''\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: One Page Report Summarizing Findings\n",
    "Overview:\n",
    "In this exercise, I explored different versions of prompts for inferring various pieces of information from product reviews and news articles using GPT-3.5. The tasks included multi-task inference (sentiment, product details, and company), summarization with a specific focus (customer service), and topic detection from a news article. By varying the prompts, I was able to compare the model's behavior in handling different types of queries.\n",
    "\n",
    "Version 1: Multi-task Inference\n",
    "This version of the prompt allowed for the extraction of multiple pieces of information (sentiment, anger, product name, and brand) from a single product review. The model responded accurately, providing a clean and concise JSON object that correctly identified the sentiment as positive, did not detect any anger, and accurately extracted the product and brand information.\n",
    "\n",
    "Strengths:\n",
    "\n",
    "Efficient for multi-tasking: The prompt allows the model to handle multiple types of inferences in one request, reducing the number of API calls.\n",
    "The format (JSON) was easy to parse programmatically, making the response well-suited for further automated processing.\n",
    "Limitations:\n",
    "\n",
    "The model relies on explicit mentions for the product and brand. In a review that lacks this information, it defaults to \"unknown,\" which can cause some gaps in extracted details.\n",
    "Version 2: Summarization with a Focus on Customer Service\n",
    "In this version, the model was tasked with summarizing the product review with an emphasis on the customer service experience. The model delivered a focused and clear summary, highlighting the aspects related to customer service (e.g., quick replacement of broken parts, good support).\n",
    "\n",
    "Strengths:\n",
    "\n",
    "The model provided a summary that accurately reflected the review's key point: the positive customer service experience.\n",
    "It was concise and remained true to the focus requested.\n",
    "Limitations:\n",
    "\n",
    "When the review contains multiple aspects (product quality, shipping, price), the model sometimes prioritizes those over the main focus, especially if they are emphasized more in the review.\n",
    "Version 3: Topic Detection in News Articles\n",
    "For this version, the model was asked to detect specific topics (e.g., NASA, employee satisfaction) from a news article about a survey. The results were accurate, identifying the topics that were clearly present in the article.\n",
    "\n",
    "Strengths:\n",
    "\n",
    "The model correctly identified key topics like \"NASA\" and \"employee satisfaction\" while ignoring irrelevant ones like \"engineering.\"\n",
    "The use of a predefined list of topics made it easy to focus the model’s attention and eliminate extraneous topics.\n",
    "Limitations:\n",
    "\n",
    "The model works well with clearly defined topics but might struggle with ambiguous or closely related topics that aren't explicitly mentioned in the text.\n",
    "If a topic is mentioned only in passing, the model might miss it, especially when competing with more prominent themes in the text.\n",
    "Key Learnings:\n",
    "Prompt Structure Matters: Well-structured prompts, especially those specifying output formats like JSON, yield clear and easily usable responses.\n",
    "Multi-task Efficiency: Combining multiple tasks in one prompt (e.g., extracting sentiment, product name, and anger) is an efficient way to save resources and time.\n",
    "Hallucinations are Rare but Possible: While the model performed well, in cases where the data is incomplete or ambiguous, there is a slight risk of hallucination or inaccurate inference.\n",
    "Targeted Summarization: The model can follow specific instructions to focus on one aspect (e.g., customer service), but it may still provide information on other areas if not careful.\n",
    "In conclusion, GPT-3.5 is a powerful tool for inferencing tasks across multiple domains, but careful prompt design is crucial to ensure accurate and relevant outputs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
