{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs for Text Transformation\n",
    "\n",
    "In this notebook, we will explore how to use Large Language Models for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Get the OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set the OpenAI API key in the OpenAI Python package\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0): \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(  # Corrected this line\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "# Example usage:\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "ChatGPT is trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\mktmi\\AppData\\Local\\Temp\\ipykernel_14712\\3809162056.py:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, me gustaría ordenar una licuadora.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish: \\ \n",
    "```Hi, I would like to order a blender```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is French.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me which language this is: \n",
    "```Combien coûte le lampadaire?```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Je veux commander un ballon de basket\n",
      "Spanish: Quiero ordenar un balón de baloncesto\n",
      "English: I want to order a basketball\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following  text to French and Spanish\n",
    "and English pirate: \\\n",
    "```I want to order a basketball```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal: ¿Le gustaría ordenar una almohada?\n",
      "Informal: ¿Te gustaría ordenar una almohada?\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following text to Spanish in both the \\\n",
    "formal and informal forms: \n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Translator\n",
    "Imagine you are in charge of IT at a large multinational e-commerce company. Users are messaging you with IT issues in all their native languages. Your staff is from all over the world and speaks only their native languages. You need a universal translator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal         \n",
    "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message (French): La performance du système est plus lente que d'habitude.\n",
      "English: \"The system performance is slower than usual.\"\n",
      "\n",
      "Korean: \"시스템 성능이 평소보다 느립니다.\" \n",
      "\n",
      "Original message (This is Spanish.): Mi monitor tiene píxeles que no se iluminan.\n",
      "English: \"My monitor has pixels that do not light up.\"\n",
      "\n",
      "Korean: \"내 모니터에는 빛나지 않는 픽셀이 있습니다.\" \n",
      "\n",
      "Original message (Italian): Il mio mouse non funziona\n",
      "English: My mouse is not working\n",
      "Korean: 내 마우스가 작동하지 않습니다 \n",
      "\n",
      "Original message (This is Polish.): Mój klawisz Ctrl jest zepsuty\n",
      "English: My Ctrl key is broken\n",
      "Korean: 제 Ctrl 키가 고장 났어요 \n",
      "\n",
      "Original message (This is Chinese.): 我的屏幕在闪烁\n",
      "English: My screen is flickering\n",
      "Korean: 내 화면이 깜박거립니다 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Original message ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Transformation\n",
    "Writing can vary based on the intended audience. ChatGPT can produce different tones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir/Madam,\n",
      "\n",
      "I am writing to bring to your attention the specifications of a standing lamp that I believe may be of interest to you. \n",
      "\n",
      "Sincerely,\n",
      "Joe\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following from slang to a business letter: \n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Conversion\n",
    "ChatGPT can translate between formats. The prompt should describe the input and output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "  <title>Restaurant Employees</title>\n",
      "</head>\n",
      "<body>\n",
      "  <table>\n",
      "    <tr>\n",
      "      <th>Name</th>\n",
      "      <th>Email</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Shyam</td>\n",
      "      <td>shyamjaiswal@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Bob</td>\n",
      "      <td>bob32@gmail.com</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Jai</td>\n",
      "      <td>jai87@gmail.com</td>\n",
      "    </tr>\n",
      "  </table>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "data_json = { \"resturant employees\" :[ \n",
    "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
    "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following python dictionary from JSON to an HTML \\\n",
    "table with column headers and title: {data_json}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "  <title>Restaurant Employees</title>\n",
       "</head>\n",
       "<body>\n",
       "  <table>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shyam</td>\n",
       "      <td>shyamjaiswal@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bob</td>\n",
       "      <td>bob32@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jai</td>\n",
       "      <td>jai87@gmail.com</td>\n",
       "    </tr>\n",
       "  </table>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spellcheck/Grammar check.\n",
    "\n",
    "Here are some examples of common grammar and spelling problems and the LLM's response. \n",
    "\n",
    "To signal to the LLM that you want it to proofread your text, you instruct the model to 'proofread' or 'proofread and correct'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The girl with the black and white puppies has a ball.\n",
      "No errors found\n",
      "No errors found.\n",
      "Their goes my freedom. There going to bring they’re suitcases.\n",
      "\n",
      "No errors found. \n",
      "\n",
      "Rewritten: \n",
      "Their goes my freedom. There going to bring they’re suitcases.\n",
      "You're going to need your notebook.\n",
      "No errors found.\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
    "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
    "  \"Your going to need you’re notebook.\",  # Homonyms\n",
    "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
    "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"Proofread and correct the following text\n",
    "    and rewrite the corrected version. If you don't find\n",
    "    and errors, just say \"No errors found\". Don't use \n",
    "    any punctuation around the text:\n",
    "    ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. One of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for the same price. It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Got this for my daughter for her birthday cuz she keeps taking \\\n",
    "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
    "it everywhere with her, and it's super soft and cute.  One of the \\\n",
    "ears is a bit lower than the other, and I don't think that was \\\n",
    "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
    "though. I think there might be other options that are bigger for \\\n",
    "the same price.  It arrived a day earlier than expected, so I got \\\n",
    "to play with it myself before I gave it to my daughter.\n",
    "\"\"\"\n",
    "prompt = f\"proofread and correct this review: ```{text}```\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip3 install redlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is the <span style='color:red;font-weight:700;text-decoration:line-through;'>original </span><span style='color:green;font-weight:700;'>updated </span>text."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from redlines import Redlines\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Example texts for comparison\n",
    "text = \"This is the original text.\"\n",
    "response = \"This is the updated text.\"\n",
    "\n",
    "# Use Redlines to compare the two strings\n",
    "diff = Redlines(text, response)\n",
    "\n",
    "# Display the difference in markdown\n",
    "display(Markdown(diff.output_markdown))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Text: \n",
       "This is the original text.\n",
       "\n",
       "Corrected and Compelling Text: \n",
       "\n",
       "In today's fast-paced world, it is crucial to stay ahead of the curve. This comprehensive review delves deep into the intricacies of the subject matter, providing valuable insights for advanced readers seeking a nuanced understanding. By adhering to the APA style guide, this review maintains a high level of credibility and professionalism. Engage with this compelling analysis to elevate your knowledge and expertise to new heights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "proofread and correct this review. Make it more compelling. \n",
    "Ensure it follows APA style guide and targets an advanced reader. \n",
    "Output in markdown format.\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "Choose Text Transformation Tasks:\n",
    "\n",
    "Think of tasks such as translation, tone transformation, grammar and spell check, or format conversion. Based on what you've done in class, explore a combination of these tasks. For example, start with translation, then adjust the tone or convert the output format.\n",
    "Create Prompts with Variations:\n",
    "\n",
    "Version 1: A direct and simple prompt. Example: “Translate this text from English to French.”\n",
    "Version 2: A more detailed and specific instruction. Example: “Translate this text from English to French and adjust the tone to be more formal.”\n",
    "Version 3: A creative prompt combining several tasks. Example: “Translate this text from English to French, adjust the tone to be formal, and correct any grammar or spelling mistakes.”\n",
    "Gather Results:\n",
    "\n",
    "For each version, run the prompt through your LLM model and analyze the outputs. This analysis is key to understanding where the model performs well or poorly.\n",
    "Compare and Document Findings:\n",
    "\n",
    "Use the Redlines library to compare the original and transformed texts for differences.\n",
    "Note if GPT generated any incorrect or unexpected results (hallucinations) during the transformation.\n",
    "Write a One-Page Report:\n",
    "\n",
    "Introduction: Briefly explain what the task was, including the types of text transformation you tested.\n",
    "Findings:\n",
    "Discuss each prompt version and highlight the differences in outputs.\n",
    "Point out any hallucinations or errors GPT made, if any.\n",
    "Note if some prompts worked better than others, and why.\n",
    "Conclusion:\n",
    "Summarize your learnings. For example, did more detailed prompts yield better results? Was GPT prone to certain types of hallucinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je voudrais commander un ordinateur portable.\n"
     ]
    }
   ],
   "source": [
    "#Version 1: Basic Translation\n",
    "prompt = \"Translate the following text from English to French: 'I would like to order a laptop.'\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je voudrais commander un ordinateur portable.\n"
     ]
    }
   ],
   "source": [
    "#Version 2: Translation with Tone Adjustment\n",
    "prompt = \"Translate the following text from English to French with a formal tone: 'I would like to order a laptop.'\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je souhaiterais commander un ordinateur portable, mais je ne connais pas le modèle.\n"
     ]
    }
   ],
   "source": [
    "#Version 3: Translation, Tone Adjustment, and Grammar Correction\n",
    "prompt = \"\"\"\n",
    "Translate the following text from English to French, adjust the tone to be formal, \n",
    "and correct any grammar mistakes: 'I would like to order a laptop but i doesn't know the model.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red;font-weight:700;text-decoration:line-through;'>I would like to order a laptop.</span><span style='color:green;font-weight:700;'>Je souhaiterais commander un ordinateur portable, mais je ne connais pas le modèle.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" #Example of Using Redlines for Comparison\n",
    "Here’s how you can compare an original and a transformed text: \"\"\"\n",
    "from redlines import Redlines\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "original_text = \"I would like to order a laptop.\"\n",
    "updated_text = response  # Response from your GPT transformation\n",
    "\n",
    "diff = Redlines(original_text, updated_text)\n",
    "display(Markdown(diff.output_markdown))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report Structure (One-Page Summary)\n",
    "Introduction:\n",
    "In this experiment, I explored using a Large Language Model for text transformation tasks, specifically focusing on translation, tone adjustment, and grammar correction. I created three different versions of prompts to test the model's performance and document the results.\n",
    "\n",
    "Findings:\n",
    "Prompt 1 (Basic Translation): The model translated the text accurately but did not adjust for tone or grammar as expected, which was not part of the task.\n",
    "Prompt 2 (Translation with Tone Adjustment): The translation was correct, and the model effectively adjusted the tone to be more formal.\n",
    "Prompt 3 (Translation, Tone Adjustment, and Grammar Correction): The model not only translated the text but also corrected the grammar mistakes in the original input. However, it added an extra sentence which was not present in the original, indicating a slight hallucination.\n",
    "Conclusion:\n",
    "I learned that more detailed and specific prompts yield better results. However, the model occasionally generated extra content (hallucinations) when correcting grammar. Tone adjustment works well, and combining tasks like translation and grammar correction can produce highly useful outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
